# Datos Fuente - F1 Data Warehouse üìä

## Descripci√≥n

Esta carpeta contiene los **archivos CSV fuente** con datos hist√≥ricos de F√≥rmula 1 desde 1950 hasta 2024. Estos archivos son el origen de datos (OLTP) que se procesan mediante el ETL para construir el Data Warehouse (OLAP).

---

## üìÅ Archivos CSV

### Dimensiones Principales

| Archivo | Registros | Descripci√≥n |
|---------|-----------|-------------|
| `drivers.csv` | 861 | Informaci√≥n de pilotos (nombre, nacionalidad, fecha nacimiento) |
| `constructors.csv` | 212 | Equipos/Constructores (nombre, nacionalidad) |
| `circuits.csv` | 77 | Circuitos (nombre, ubicaci√≥n, coordenadas GPS) |
| `status.csv` | 139 | Estados de finalizaci√≥n (Finished, Accident, Engine, etc.) |
| `seasons.csv` | 75 | Temporadas (1950-2024) |

### Datos de Carreras

| Archivo | Registros | Descripci√≥n |
|---------|-----------|-------------|
| `races.csv` | 1,125 | Informaci√≥n de Grandes Premios (fecha, circuito, a√±o) |
| `results.csv` | 26,759 | Resultados de carreras (posici√≥n, puntos, tiempo) |
| `qualifying.csv` | 10,494 | Resultados de clasificaci√≥n (Q1, Q2, Q3) |
| `sprint_results.csv` | 360 | Resultados de carreras sprint (2021+) |

### Datos Detallados

| Archivo | Registros | Descripci√≥n |
|---------|-----------|-------------|
| `lap_times.csv` | 589,081 | Tiempos de vuelta detallados |
| `pit_stops.csv` | 11,371 | Paradas en boxes (duraci√≥n, vuelta) |
| `driver_standings.csv` | 34,863 | Clasificaci√≥n de pilotos por carrera |
| `constructor_standings.csv` | 13,391 | Clasificaci√≥n de constructores por carrera |
| `constructor_results.csv` | 12,625 | Resultados agregados por constructor |

---

## üìä Estad√≠sticas Generales

- **Total de archivos**: 14 CSV
- **Total de registros**: ~701,433 filas
- **Per√≠odo cubierto**: 1950 - 2024 (75 temporadas)
- **Tama√±o aproximado**: ~150 MB
- **Formato**: CSV con separador `,`
- **Encoding**: UTF-8
- **Valores nulos**: Representados como `\N`

---

## üîÑ Uso en el ETL

Estos archivos son le√≠dos por el proceso ETL en la **fase de extracci√≥n**:

```python
# Extract (etl/extract/extractor.py)
data = pd.read_csv('data/drivers.csv', na_values=['\\N'])
```

### Mapeo a Dimensiones

| CSV Fuente | Tabla Destino DW | Tipo |
|------------|------------------|------|
| `drivers.csv` | `dim_piloto` | Dimensi√≥n |
| `constructors.csv` | `dim_constructor` | Dimensi√≥n |
| `circuits.csv` | `dim_circuito` | Dimensi√≥n |
| `status.csv` | `dim_status` | Dimensi√≥n |
| `races.csv` | `dim_carrera` + `dim_tiempo` | Dimensi√≥n |
| `results.csv` + `races.csv` | `fact_resultados_carrera` | Hecho |

---

## üìù Formato de Datos

### Ejemplo: drivers.csv
```csv
driverId,driverRef,number,code,forename,surname,dob,nationality,url
1,hamilton,44,HAM,Lewis,Hamilton,1985-01-07,British,http://en.wikipedia.org/wiki/Lewis_Hamilton
2,alonso,14,ALO,Fernando,Alonso,1981-07-29,Spanish,http://en.wikipedia.org/wiki/Fernando_Alonso
```

### Ejemplo: results.csv
```csv
resultId,raceId,driverId,constructorId,number,grid,position,positionText,points,laps,time,milliseconds,fastestLap,rank,fastestLapTime,fastestLapSpeed,statusId
1,18,1,1,22,1,1,1,10.0,58,1:34:50.616,5690616,39,2,1:27.452,218.300,1
```

### Valores Especiales

- **`\N`**: Representa valores nulos o no disponibles
- **Posiciones**: N√∫meros enteros (1 = primero, 2 = segundo, etc.)
- **Tiempos**: En formato `mm:ss.sss` o milisegundos
- **Fechas**: Formato ISO `YYYY-MM-DD`

---

## üîç An√°lisis Exploratorio

Para analizar estos archivos antes de cargarlos al DW:

```bash
# Ejecutar script de an√°lisis
python3 describe_tables.py
```

Este script proporciona:
- Conteo de filas y columnas
- Tipos de datos
- Valores nulos
- Estad√≠sticas descriptivas
- Muestras de datos

---

## üìö Fuente de Datos

**Dataset**: Ergast Developer API  
**URL**: http://ergast.com/mrd/  
**Licencia**: Creative Commons Attribution-NonCommercial  
**√öltima actualizaci√≥n**: 2024  
**Mantenedor**: Ergast Motor Racing Database  

### C√≥mo actualizar los datos

1. Descargar nuevos CSVs desde Ergast API
2. Reemplazar archivos en esta carpeta
3. Ejecutar ETL completo: `python3 etl/run_etl_hefesto.py`

---

## ‚ö†Ô∏è Notas Importantes

1. **No modificar manualmente**: Estos archivos son la fuente de verdad (OLTP)
2. **Backup recomendado**: Mantener copia de los CSVs originales
3. **Integridad**: Relaciones entre CSVs mediante IDs (driverId, raceId, etc.)
4. **Calidad**: Algunos datos hist√≥ricos pueden ser incompletos (pre-1980)
5. **Consistencia**: Respetar formato CSV original para el ETL

---

## üöÄ Pr√≥ximos Pasos

1. ‚úÖ Analizar datos con `describe_tables.py`
2. ‚úÖ Configurar base de datos PostgreSQL
3. ‚úÖ Ejecutar ETL: `python3 etl/run_etl_hefesto.py`
4. ‚úÖ Validar datos en el Data Warehouse
5. ‚úÖ Crear consultas anal√≠ticas

---

**Ver tambi√©n:**
- [`readme.md`](../readme.md) - Documentaci√≥n principal
- [`etl/README_ETL.md`](../etl/README_ETL.md) - Detalles del ETL
- [`METODOLOGIA_HEFESTO.md`](../METODOLOGIA_HEFESTO.md) - Metodolog√≠a aplicada
